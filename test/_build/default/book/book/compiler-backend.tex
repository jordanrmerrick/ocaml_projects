\hypertarget{the-compiler-backend-byte-code-and-native-code}{%
\section{The Compiler Backend: Bytecode and Native
code}\label{the-compiler-backend-byte-code-and-native-code}}

Once OCaml has passed the type checking stage, it can stop emitting
syntax and type errors and begin the process of compiling the
well-formed modules into executable code.

In this chapter, we'll cover the following topics:

\begin{itemize}
\item
  The untyped intermediate lambda code where pattern matching is
  optimized
\item
  The bytecode \passthrough{\lstinline!ocamlc!} compiler and
  \passthrough{\lstinline!ocamlrun!} interpreter
\item
  The native code \passthrough{\lstinline!ocamlopt!} code generator, and
  debugging and profiling native code
\end{itemize}

\hypertarget{the-untyped-lambda-form}{%
\subsection{The Untyped Lambda Form}\label{the-untyped-lambda-form}}

The first code generation phase eliminates all the static type
information into a simpler intermediate \emph{lambda form}. The lambda
form discards higher-level constructs such as modules and objects and
replaces them with simpler values such as records and function pointers.
Pattern matches are also analyzed and compiled into highly optimized
automata.\index{lambda form
code/basics of}\protect\hypertarget{CPuntype}{}{compilation
process/untyped lambda form}

The lambda form is the key stage that discards the OCaml type
information and maps the source code to the runtime memory model
described in
\href{runtime-memory-layout.html\#memory-representation-of-values}{Memory
Representation Of Values}. This stage also performs some optimizations,
most notably converting pattern-match statements into more optimized but
low-level statements.

\hypertarget{pattern-matching-optimization}{%
\subsubsection{Pattern Matching
Optimization}\label{pattern-matching-optimization}}

The compiler dumps the lambda form in an s-expression syntax if you add
the {-dlambda} directive to the command line. Let's use this to learn
more about how the OCaml pattern-matching engine works by building three
different pattern matches and comparing their lambda
forms.\index{pattern matching/optimization in lambda form code}\index{lambda form
code/pattern matching optimization}

Let's start by creating a straightforward exhaustive pattern match using
four normal variants:

\begin{lstlisting}[language=Caml]
type t = | Alice | Bob | Charlie | David

let test v =
  match v with
  | Alice   -> 100
  | Bob     -> 101
  | Charlie -> 102
  | David   -> 103
\end{lstlisting}

The lambda output for this code looks like this:

\begin{lstlisting}[language=bash]
$ ocamlc -dlambda -c pattern_monomorphic_large.ml 2>&1
(setglobal Pattern_monomorphic_large!
  (let
    (test/85 =
       (function v/86 : int
         (switch* v/86
          case int 0: 100
          case int 1: 101
          case int 2: 102
          case int 3: 103)))
    (makeblock 0 test/85)))
\end{lstlisting}

It's not important to understand every detail of this internal form, and
it is explicitly undocumented since it can change across compiler
revisions. Despite these caveats, some interesting points emerge from
reading it:

\begin{itemize}
\item
  There are no mention of modules or types any more. Global values are
  created via \passthrough{\lstinline!setglobal!}, and OCaml values are
  constructed by \passthrough{\lstinline!makeblock!}. The blocks are the
  runtime values you should remember from
  \href{runtime-memory-layout.html\#memory-representation-of-values}{Memory
  Representation Of Values}.
\item
  The pattern match has turned into a switch case that jumps to the
  right case depending on the header tag of \passthrough{\lstinline!v!}.
  Recall that variants without parameters are stored in memory as
  integers in the order which they appear. The pattern-matching engine
  knows this and has transformed the pattern into an efficient jump
  table.
\item
  Values are addressed by a unique name that distinguishes shadowed
  values by appending a number (e.g., \passthrough{\lstinline!v/1014!}).
  The type safety checks in the earlier phase ensure that these
  low-level accesses never violate runtime memory safety, so this layer
  doesn't do any dynamic checks. Unwise use of unsafe features such as
  the \passthrough{\lstinline!Obj.magic!} module can still easily induce
  crashes at this level.
\end{itemize}

The compiler computes a jump table in order to handle all four cases. If
we drop the number of variants to just two, then there's no need for the
complexity of computing this table:

\begin{lstlisting}[language=Caml]
type t = | Alice | Bob

let test v =
  match v with
  | Alice   -> 100
  | Bob     -> 101
\end{lstlisting}

The lambda output for this code is now quite different:

\begin{lstlisting}[language=bash]
$ ocamlc -dlambda -c pattern_monomorphic_small.ml 2>&1
(setglobal Pattern_monomorphic_small!
  (let (test/83 = (function v/84 : int (if (!= v/84 0) 101 100)))
    (makeblock 0 test/83)))
\end{lstlisting}

The compiler emits simpler conditional jumps rather than setting up a
jump table, since it statically determines that the range of possible
variants is small enough. Finally, let's look at the same code, but with
polymorphic variants instead of normal variants:

\begin{lstlisting}[language=Caml]
let test v =
  match v with
  | `Alice   -> 100
  | `Bob     -> 101
  | `Charlie -> 102
  | `David   -> 103
  | `Eve     -> 104
\end{lstlisting}

The lambda form for this also shows up the runtime representation of
polymorphic variants:

\begin{lstlisting}[language=bash]
$ ocamlc -dlambda -c pattern_polymorphic.ml 2>&1
(setglobal Pattern_polymorphic!
  (let
    (test/80 =
       (function v/81 : int
         (if (!= v/81 3306965)
           (if (>= v/81 482771474) (if (>= v/81 884917024) 100 102)
             (if (>= v/81 3457716) 104 103))
           101)))
    (makeblock 0 test/80)))
\end{lstlisting}

We mentioned in \href{variants.html\#variants}{Variants} that pattern
matching over polymorphic variants is slightly less efficient, and it
should be clearer why this is the case now. Polymorphic variants have a
runtime value that's calculated by hashing the variant name, and so the
compiler can't use a jump table as it does for normal variants. Instead,
it creates a decision tree that compares the hash values against the
input variable in as few comparisons as possible.
\index{pattern matching/fundamental
algorithms in}

\hypertarget{learning-more-about-pattern-matching-compilation}{%
\paragraph{Learning More About Pattern Matching
Compilation}\label{learning-more-about-pattern-matching-compilation}}

Pattern matching is an important part of OCaml programming. You'll often
encounter deeply nested pattern matches over complex data structures in
real code. A good paper that describes the fundamental algorithms
implemented in OCaml is
\href{http://dl.acm.org/citation.cfm?id=507641}{``Optimizing pattern
matching''} by Fabrice Le Fessant and Luc Maranget.

The paper describes the backtracking algorithm used in classical pattern
matching compilation, and also several OCaml-specific optimizations,
such as the use of exhaustiveness information and control flow
optimizations via static exceptions.

It's not essential that you understand all of this just to use pattern
matching, of course, but it'll give you insight as to why pattern
matching is such a lightweight language construct to use in OCaml code.

\hypertarget{benchmarking-pattern-matching}{%
\subsubsection{Benchmarking Pattern
Matching}\label{benchmarking-pattern-matching}}

Let's benchmark these three pattern-matching techniques to quantify
their runtime costs more accurately. The
\passthrough{\lstinline!Core\_bench!} module runs the tests thousands of
times and also calculates statistical variance of the results. You'll
need to \passthrough{\lstinline!opam install core\_bench!} to get the
library:\index{pattern
matching/benchmarking of}\index{lambda form code/pattern matching
benchmarking}

\begin{lstlisting}[language=Caml]
open Core
open Core_bench

type t = | Alice | Bob
type s = | A | B | C | D | E

let polymorphic_pattern () =
  let test v =
    match v with
    | `Alice   -> 100
    | `Bob     -> 101
    | `Charlie -> 102
    | `David   -> 103
    | `Eve     -> 104
  in
  List.iter ~f:(fun v -> ignore(test v))
    [`Alice; `Bob; `Charlie; `David]

let monomorphic_pattern_small () =
  let test v =
    match v with
    | Alice   -> 100
    | Bob     -> 101 in
  List.iter ~f:(fun v -> ignore(test v))
    [ Alice; Bob ]

let monomorphic_pattern_large () =
  let test v =
    match v with
    | A       -> 100
    | B       -> 101
    | C       -> 102
    | D       -> 103
    | E       -> 104
  in
  List.iter ~f:(fun v -> ignore(test v))
    [ A; B; C; D ]

let tests = [
  "Polymorphic pattern", polymorphic_pattern;
  "Monomorphic larger pattern", monomorphic_pattern_large;
  "Monomorphic small pattern", monomorphic_pattern_small;
]

let () =
  List.map tests ~f:(fun (name,test) -> Bench.Test.create ~name test)
  |> Bench.make_command
  |> Command.run
\end{lstlisting}

Building and executing this example will run for around 30 seconds by
default, and you'll see the results summarized in a neat table:

\begin{lstlisting}
(executable
  (name      bench_patterns)
  (modules   bench_patterns)
  (libraries core_bench))
\end{lstlisting}

\begin{lstlisting}[language=bash]
$ dune build bench_patterns.exe
$ ./_build/default/bench_patterns.exe -ascii -quota 0.25
Estimated testing time 750ms (3 benchmarks x 250ms). Change using -quota SECS.

  Name                         Time/Run   Percentage
 ---------------------------- ---------- ------------
  Polymorphic pattern           24.93ns       89.45%
  Monomorphic larger pattern    27.88ns      100.00%
  Monomorphic small pattern     10.84ns       38.90%
\end{lstlisting}

These results confirm the performance hypothesis that we obtained
earlier by inspecting the lambda code. The shortest running time comes
from the small conditional pattern match, and polymorphic variant
pattern matching is the slowest. There isn't a hugely significant
difference in these examples, but you can use the same techniques to
peer into the innards of your own source code and narrow down any
performance hotspots.

The lambda form is primarily a stepping stone to the bytecode executable
format that we'll cover next. It's often easier to look at the textual
output from this stage than to wade through the native assembly code
from compiled executables.~

\hypertarget{generating-portable-bytecode}{%
\subsection{Generating Portable
Bytecode}\label{generating-portable-bytecode}}

After the lambda form has been generated, we are very close to having
executable code. The OCaml toolchain branches into two separate
compilers at this point. We'll describe the bytecode compiler first,
which consists of two pieces:
\index{OCaml toolchain/ocamlrun}\index{OCaml
toolchain/ocamlc}\index{bytecode compiler/tools used}\protect\hypertarget{CPportbyte}{}{compilation
process/portable bytecode}

\begin{description}
\tightlist
\item[\texttt{ocamlc}]
Compiles files into a bytecode that is a close mapping to the lambda
form
\item[\texttt{ocamlrun}]
A portable interpreter that executes the bytecode
\end{description}

The big advantage of using bytecode is simplicity, portability, and
compilation speed. The mapping from the lambda form to bytecode is
straightforward, and this results in predictable (but slow) execution
speed.

The bytecode interpreter implements a stack-based virtual machine. The
OCaml stack and an associated accumulator store values that consist
of:\index{bytecode
compiler/values stored by}\index{code offset values}\index{block
values}\index{long values}\index{values/stored by bytecode compiler}

\begin{description}
\tightlist
\item[long]
Values that correspond to an OCaml \passthrough{\lstinline!int!} type
\item[block]
Values that contain the block header and a memory address with the data
fields that contain further OCaml values indexed by an integer
\item[code offset]
Values that are relative to the starting code address
\end{description}

The interpreter virtual machine only has seven registers in total: -
program counter, - stack, exception and argument pointers, -
accumulator, - environment and global data.

You can display the bytecode instructions in textual form via
\passthrough{\lstinline!-dinstr!}. Try this on one of our earlier
pattern-matching examples:

\begin{lstlisting}[language=bash]
$ ocamlc -dinstr pattern_monomorphic_small.ml 2>&1
    branch L2
L1: acc 0
    push
    const 0
    neqint
    branchifnot L3
    const 101
    return 1
L3: const 100
    return 1
L2: closure L1, 0
    push
    acc 0
    makeblock 1, 0
    pop 1
    setglobal Pattern_monomorphic_small!
\end{lstlisting}

The preceding bytecode has been simplified from the lambda form into a
set of simple instructions that are executed serially by the
interpreter.

There are around 140 instructions in total, but most are just minor
variants of commonly encountered operations (e.g., function application
at a specific arity). You can find full details
\href{http://cadmium.x9c.fr/distrib/caml-instructions.pdf}{online}.
\index{bytecode
compiler/instruction set for}

\hypertarget{where-did-the-bytecode-instruction-set-come-from}{%
\subsubsection{Where Did the Bytecode Instruction Set Come
From?}\label{where-did-the-bytecode-instruction-set-come-from}}

The bytecode interpreter is much slower than compiled native code, but
is still remarkably performant for an interpreter without a JIT
compiler. Its efficiency can be traced back to Xavier Leroy's
ground-breaking work in 1990,
\href{http://hal.inria.fr/docs/00/07/00/49/PS/RT-0117.ps}{``The ZINC
experiment: An Economical Implementation of the ML Language''.}

This paper laid the theoretical basis for the implementation of an
instruction set for a strictly evaluated functional language such as
OCaml. The bytecode interpreter in modern OCaml is still based on the
ZINC model. The native code compiler uses a different model since it
uses CPU registers for function calls instead of always passing
arguments on the stack, as the bytecode interpreter does.

Understanding the reasoning behind the different implementations of the
bytecode interpreter and the native compiler is a very useful exercise
for any budding language hacker.

\hypertarget{compiling-and-linking-bytecode}{%
\subsubsection{Compiling and Linking
Bytecode}\label{compiling-and-linking-bytecode}}

The \passthrough{\lstinline!ocamlc!} command compiles individual
\passthrough{\lstinline!ml!} files into bytecode files that have a
\passthrough{\lstinline!cmo!} extension. The compiled bytecode files are
matched with the associated \passthrough{\lstinline!cmi!} interface,
which contains the type signature exported to other compilation units.
\index{bytecode compiler/compiling and linking code}

A typical OCaml library consists of multiple source files, and hence
multiple \passthrough{\lstinline!cmo!} files that all need to be passed
as command-line arguments to use the library from other code. The
compiler can combine these multiple files into a more convenient single
archive file by using the \passthrough{\lstinline!-a!} flag. Bytecode
archives are denoted by the \passthrough{\lstinline!cma!} extension.

The individual objects in the library are linked as regular
\passthrough{\lstinline!cmo!} files in the order specified when the
library file was built. If an object file within the library isn't
referenced elsewhere in the program, then it isn't included in the final
binary unless the \passthrough{\lstinline!-linkall!} flag forces its
inclusion. This behavior is analogous to how C handles object files and
archives (\passthrough{\lstinline!.o!} and \passthrough{\lstinline!.a!},
respectively).

The bytecode files are then linked together with the OCaml standard
library to produce an executable program. The order in which
\passthrough{\lstinline!.cmo!} arguments are presented on the command
line defines the order in which compilation units are initialized at
runtime. Remember that OCaml has no single
\passthrough{\lstinline!main!} function like C, so this link order is
more important than in C programs.

\hypertarget{executing-bytecode}{%
\subsubsection{Executing Bytecode}\label{executing-bytecode}}

The bytecode runtime comprises three parts: the bytecode interpreter,
GC, and a set of C functions that implement the primitive operations.
The bytecode contains instructions to call these C functions when
required.

The OCaml linker produces bytecode that targets the standard OCaml
runtime by default, and so needs to know about any C functions that are
referenced from other libraries that aren't loaded by default.

Information about these extra libraries can be specified while linking a
bytecode archive:

\begin{lstlisting}
$ ocamlc -a -o mylib.cma a.cmo b.cmo -dllib -lmylib
\end{lstlisting}

The \passthrough{\lstinline!dllib!} flag embeds the arguments in the
archive file. Any subsequent packages linking this archive will also
include the extra C linking directive. This in turn lets the interpreter
dynamically load the external library symbols when it executes the
bytecode.

You can also generate a complete standalone executable that bundles the
\passthrough{\lstinline!ocamlrun!} interpreter with the bytecode in a
single binary. This is known as a \emph{custom runtime} mode and is
built as follows: \index{custom runtime mode}

\begin{lstlisting}
$ ocamlc -a -o mylib.cma -custom a.cmo b.cmo -cclib -lmylib
\end{lstlisting}

OCamlbuild takes care of many of these details with its built-in rules.
The \passthrough{\lstinline!\%.byte!} rule that you've been using
throughout the book builds a bytecode executable, and adding the
\passthrough{\lstinline!custom!} tag will bundle the interpreter with
it, too. \index{\%.byte rule}

The custom mode is the most similar mode to native code compilation, as
both generate standalone executables. There are quite a few other
options available for compiling bytecode (notably with shared libraries
or building custom runtimes). Full details can be found in the
\href{http://caml.inria.fr/pub/docs/manual-ocaml/manual022.html}{OCaml}.

\hypertarget{embedding-ocaml-bytecode-in-c}{%
\subsubsection{Embedding OCaml Bytecode in
C}\label{embedding-ocaml-bytecode-in-c}}

A consequence of using the bytecode compiler is that the final link
phase must be performed by \passthrough{\lstinline!ocamlc!}. However,
you might sometimes want to embed your OCaml code inside an existing C
application. OCaml also supports this mode of operation via the
{-output-obj} directive.\index{C object files}

This mode causes \passthrough{\lstinline!ocamlc!} to output an object
file containing the bytecode for the OCaml part of the program, as well
as a \passthrough{\lstinline!caml\_startup!} function. All of the OCaml
modules are linked into this object file as bytecode, just as they would
be for an executable.

This object file can then be linked with C code using the standard C
compiler, needing only the bytecode runtime library (which is installed
as \passthrough{\lstinline!libcamlrun.a!}). Creating an executable just
requires you to link the runtime library with the bytecode object file.
Here's an example to show how it all fits together.

Create two OCaml source files that contain a single print line:

\begin{lstlisting}[language=Caml]
let () = print_endline "hello embedded world 1"
\end{lstlisting}

\begin{lstlisting}[language=Caml]
let () = print_endline "hello embedded world 2"
\end{lstlisting}

Next, create a C file to be your main entry point:

\begin{lstlisting}
#include <stdio.h>
#include <caml/alloc.h>
#include <caml/mlvalues.h>
#include <caml/memory.h>
#include <caml/callback.h>

int
main (int argc, char **argv)
{
  printf("Before calling OCaml\n");
  fflush(stdout);
  caml_startup (argv);
  printf("After calling OCaml\n");
  return 0;
}
\end{lstlisting}

Now compile the OCaml files into a standalone object file:

\begin{lstlisting}[language=bash]
$ rm -f embed_out.c
$ ocamlc -output-obj -o embed_out.o embed_me1.ml embed_me2.ml
\end{lstlisting}

After this point, you no longer need the OCaml compiler, as
\passthrough{\lstinline!embed\_out.o!} has all of the OCaml code
compiled and linked into a single object file. Compile an output binary
using \passthrough{\lstinline!gcc!} to test this out:

\begin{lstlisting}
$ gcc -fPIC -Wall -I`ocamlc -where` -L`ocamlc -where` -ltermcap -lm -ldl \
  -o finalbc.native main.c embed_out.o -lcamlrun
$ ./finalbc.native
Before calling OCaml
hello embedded world 1
hello embedded world 2
After calling OCaml
\end{lstlisting}

You can inspect the commands that \passthrough{\lstinline!ocamlc!} is
invoking by adding \passthrough{\lstinline!-verbose!} to the command
line to help figure out the GCC command line if you get stuck. You can
even obtain the C source code to the
\passthrough{\lstinline!-output-obj!} result by specifying a
\passthrough{\lstinline!.c!} output file extension instead of the
\passthrough{\lstinline!.o!} we used earlier:

\begin{lstlisting}[language=bash]
$ ocamlc -output-obj -o embed_out.c embed_me1.ml embed_me2.ml
\end{lstlisting}

Embedding OCaml code like this lets you write OCaml that interfaces with
any environment that works with a C compiler. You can even cross back
from the C code into OCaml by using the
\passthrough{\lstinline!Callback!} module to register named entry points
in the OCaml code. This is explained in detail in the
\href{http://caml.inria.fr/pub/docs/manual-ocaml/manual033.html\#toc149}{interfacing
with C} section of the OCaml manual. ~

\hypertarget{compiling-fast-native-code}{%
\subsection{Compiling Fast Native
Code}\label{compiling-fast-native-code}}

The native code compiler is ultimately the tool that most production
OCaml code goes through. It compiles the lambda form into fast native
code executables, with cross-module inlining and additional optimization
passes that the bytecode interpreter doesn't perform. Care is taken to
ensure compatibility with the bytecode runtime, so the same code should
run identically when compiled with either toolchain.
\index{cmi files}\index{files/cmi
files}\index{cmx files}\index{files/cmx files}\index{o files}\index{files/o
files}\index{OCaml toolchain/ocamlopt}\index{native-code compiler/benefits
of}\protect\hypertarget{CPfast}{}{compilation process/fast native code}

The \passthrough{\lstinline!ocamlopt!} command is the frontend to the
native code compiler and has a very similar interface to
\passthrough{\lstinline!ocamlc!}. It also accepts
\passthrough{\lstinline!ml!} and \passthrough{\lstinline!mli!} files,
but compiles them to:

\begin{itemize}
\item
  A \passthrough{\lstinline!.o!} file containing native object code
\item
  A \passthrough{\lstinline!.cmx!} file containing extra information for
  linking and cross-module optimization
\item
  A \passthrough{\lstinline!.cmi!} compiled interface file that is the
  same as the bytecode compiler
\end{itemize}

When the compiler links modules together into an executable, it uses the
contents of the \passthrough{\lstinline!cmx!} files to perform
cross-module inlining across compilation units. This can be a
significant speedup for standard library functions that are frequently
used outside of their module.

Collections of \passthrough{\lstinline!.cmx!} and
\passthrough{\lstinline!.o!} files can also be be linked into a
\passthrough{\lstinline!.cmxa!} archive by passing the
\passthrough{\lstinline!-a!} flag to the compiler. However, unlike the
bytecode version, you must keep the individual
\passthrough{\lstinline!cmx!} files in the compiler search path so that
they are available for cross-module inlining. If you don't do this, the
compilation will still succeed, but you will have missed out on an
important optimization and have slower binaries.

\hypertarget{inspecting-assembly-output}{%
\subsubsection{Inspecting Assembly
Output}\label{inspecting-assembly-output}}

The native code compiler generates assembly language that is then passed
to the system assembler for compiling into object files. You can get
\passthrough{\lstinline!ocamlopt!} to output the assembly by passing the
\passthrough{\lstinline!-S!} flag to the compiler command
line.\index{native-code compiler/inspecting assembly output}

The assembly code is highly architecture-specific, so the following
discussion assumes an Intel or AMD 64-bit platform. We've generated the
example code using \passthrough{\lstinline!-inline 20!} and
\passthrough{\lstinline!-nodynlink!} since it's best to generate
assembly code with the full optimizations that the compiler supports.
Even though these optimizations make the code a bit harder to read, it
will give you a more accurate picture of what executes on the CPU. Don't
forget that you can use the lambda code from earlier to get a slightly
higher-level picture of the code if you get lost in the more verbose
assembly.

\hypertarget{the-impact-of-polymorphic-comparison}{%
\paragraph{The impact of polymorphic
comparison}\label{the-impact-of-polymorphic-comparison}}

We warned you in
\href{maps-and-hashtables.html\#maps-and-hash-tables}{Maps And Hash
Tables} that using polymorphic comparison is both convenient and
perilous. Let's look at precisely what the difference is at the assembly
language level now.\index{polymorphic comparisons}

First let's create a comparison function where we've explicitly
annotated the types, so the compiler knows that only integers are being
compared:

\begin{lstlisting}[language=Caml]
let cmp (a:int) (b:int) =
  if a > b then a else b
\end{lstlisting}

Now compile this into assembly and read the resulting
\passthrough{\lstinline!compare\_mono.S!} file. This file extension may
be lowercase on some platforms such as Linux:

\begin{lstlisting}[language=bash]
\end{lstlisting}

If you've never seen assembly language before, then the contents may be
rather scary. While you'll need to learn x86 assembly to fully
understand it, we'll try to give you some basic instructions to spot
patterns in this section. The excerpt of the implementation of the
\passthrough{\lstinline!cmp!} function can be found below:

\begin{lstlisting}
_camlCompare_mono__cmp_1008:
        .cfi_startproc
.L101:
        cmpq    %rbx, %rax
        jle     .L100
        ret
        .align  2
.L100:
        movq    %rbx, %rax
        ret
        .cfi_endproc
\end{lstlisting}

The \passthrough{\lstinline!\_camlCompare\_mono\_\_cmp\_1008!} is an
assembly label that has been computed from the module name
(\passthrough{\lstinline!Compare\_mono!}) and the function name
(\passthrough{\lstinline!cmp\_1008!}). The numeric suffix for the
function name comes straight from the lambda form (which you can inspect
using \passthrough{\lstinline!-dlambda!}, but in this case isn't
necessary).

The arguments to \passthrough{\lstinline!cmp!} are passed in the
\passthrough{\lstinline!\%rbx!} and \passthrough{\lstinline!\%rax!}
registers, and compared using the \passthrough{\lstinline!jle!} ``jump
if less than or equal'' instruction. This requires both the arguments to
be immediate integers to work. Now let's see what happens if our OCaml
code omits the type annotations and is a polymorphic comparison instead:

\begin{lstlisting}[language=Caml]
let cmp a b =
  if a > b then a else b
\end{lstlisting}

Compiling this code with \passthrough{\lstinline!-S!} results in a
significantly more complex assembly output for the same function:

\begin{lstlisting}
_camlCompare_poly__cmp_1008:
        .cfi_startproc
        subq    $24, %rsp
        .cfi_adjust_cfa_offset  24
.L101:
        movq    %rax, 8(%rsp)
        movq    %rbx, 0(%rsp)
        movq    %rax, %rdi
        movq    %rbx, %rsi
        leaq    _caml_greaterthan(%rip), %rax
        call    _caml_c_call
.L102:
        leaq    _caml_young_ptr(%rip), %r11
        movq    (%r11), %r15
        cmpq    $1, %rax
        je      .L100
        movq    8(%rsp), %rax
        addq    $24, %rsp
        .cfi_adjust_cfa_offset  -24
        ret
        .cfi_adjust_cfa_offset  24
        .align  2
.L100:
        movq    0(%rsp), %rax
        addq    $24, %rsp
        .cfi_adjust_cfa_offset  -24
        ret
        .cfi_adjust_cfa_offset  24
        .cfi_endproc
\end{lstlisting}

The \passthrough{\lstinline!.cfi!} directives are assembler hints that
contain Call Frame Information that lets the debugger provide more
sensible backtraces, and they have no effect on runtime performance.
Notice that the rest of the implementation is no longer a simple
register comparison. Instead, the arguments are pushed on the stack (the
\passthrough{\lstinline!\%rsp!} register), and a C function call is
invoked by placing a pointer to
\passthrough{\lstinline!caml\_greaterthan!} in
\passthrough{\lstinline!\%rax!} and jumping to
\passthrough{\lstinline!caml\_c\_call!}. \index{backtraces}

OCaml on x86\_64 architectures caches the location of the minor heap in
the \passthrough{\lstinline!\%r15!} register since it's so frequently
referenced in OCaml functions. The minor heap pointer can also be
changed by the C code that's being called (e.g., when it allocates OCaml
values), and so \passthrough{\lstinline!\%r15!} is restored after
returning from the \passthrough{\lstinline!caml\_greaterthan!} call.
Finally, the return value of the comparison is popped from the stack and
returned.

\hypertarget{benchmarking-polymorphic-comparison}{%
\paragraph{Benchmarking polymorphic
comparison}\label{benchmarking-polymorphic-comparison}}

You don't have to fully understand the intricacies of assembly language
to see that this polymorphic comparison is much heavier than the simple
monomorphic integer comparison from earlier. Let's confirm this
hypothesis again by writing a quick
\passthrough{\lstinline!Core\_bench!} test with both functions:

\begin{lstlisting}[language=Caml]
open Core
open Core_bench

let polymorphic_compare () =
  let cmp a b = if a > b then a else b in
  for i = 0 to 1000 do
    ignore(cmp 0 i)
  done

let monomorphic_compare () =
  let cmp (a:int) (b:int) =
    if a > b then a else b in
  for i = 0 to 1000 do
    ignore(cmp 0 i)
  done

let tests =
  [ "Polymorphic comparison", polymorphic_compare;
    "Monomorphic comparison", monomorphic_compare ]

let () =
  List.map tests ~f:(fun (name,test) -> Bench.Test.create ~name test)
  |> Bench.make_command
  |> Command.run
\end{lstlisting}

Running this shows quite a significant runtime difference between the
two:

\begin{lstlisting}
(executable
  (name      bench_poly_and_mono)
  (modules   bench_poly_and_mono)
  (libraries core_bench))
\end{lstlisting}

\begin{lstlisting}[language=bash]
$ dune build bench_poly_and_mono.exe
$ ./_build/default/bench_poly_and_mono.exe -ascii -quota 1
Estimated testing time 2s (2 benchmarks x 1s). Change using -quota SECS.

  Name                        Time/Run   Percentage
 ------------------------ ------------- ------------
  Polymorphic comparison   18_402.43ns      100.00%
  Monomorphic comparison      734.22ns        3.99%
\end{lstlisting}

We see that the polymorphic comparison is close to 20 times slower!
These results shouldn't be taken too seriously, as this is a very narrow
test that, like all such microbenchmarks, isn't representative of more
complex codebases. However, if you're building numerical code that runs
many iterations in a tight inner loop, it's worth manually peering at
the produced assembly code to see if you can hand-optimize it.

\hypertarget{debugging-native-code-binaries}{%
\subsubsection{Debugging Native Code
Binaries}\label{debugging-native-code-binaries}}

The native code compiler builds executables that can be debugged using
conventional system debuggers such as GNU \passthrough{\lstinline!gdb!}.
You need to compile your libraries with the \passthrough{\lstinline!-g!}
option to add the debug information to the output, just as you need to
with C compilers. \index{debugging/native code
binaries}\index{native-code compiler/debugging binaries}

Extra debugging information is inserted into the output assembly when
the library is compiled in debug mode. These include the CFI stubs you
will have noticed in the profiling output earlier
(\passthrough{\lstinline!.cfi\_start\_proc!} and
\passthrough{\lstinline!.cfi\_end\_proc!} to delimit an OCaml function
call, for example).

\hypertarget{understanding-name-mangling}{%
\paragraph{Understanding name
mangling}\label{understanding-name-mangling}}

So how do you refer to OCaml functions in an interactive debugger like
\passthrough{\lstinline!gdb!}? The first thing you need to know is how
OCaml function names compile down to symbol names in the compiled object
files, a procedure generally called \emph{name
mangling}.\index{gdb debugger}\index{debugging/interactive
debuggers}\index{functions/name mangling of}\index{name mangling}

Each OCaml source file is compiled into a native object file that must
export a unique set of symbols to comply with the C binary interface.
This means that any OCaml values that may be used by another compilation
unit need to be mapped onto a symbol name. This mapping has to account
for OCaml language features such as nested modules, anonymous functions,
and variable names that shadow one another.

The conversion follows some straightforward rules for named variables
and functions:

\begin{itemize}
\item
  The symbol is prefixed by \passthrough{\lstinline!caml!} and the local
  module name, with dots replaced by underscores.
\item
  This is followed by a double \passthrough{\lstinline!\_\_!} suffix and
  the variable name.
\item
  The variable name is also suffixed by a \passthrough{\lstinline!\_!}
  and a number. This is the result of the lambda compilation, which
  replaces each variable name with a unique value within the module. You
  can determine this number by examining the
  \passthrough{\lstinline!-dlambda!} output from
  \passthrough{\lstinline!ocamlopt!}.
\end{itemize}

Anonymous functions are hard to predict without inspecting intermediate
compiler output. If you need to debug them, it's usually easier to
modify the source code to let-bind the anonymous function to a variable
name.

\hypertarget{interactive-breakpoints-with-the-gnu-debugger}{%
\paragraph{Interactive breakpoints with the GNU
debugger}\label{interactive-breakpoints-with-the-gnu-debugger}}

Let's see name mangling in action with some interactive debugging using
GNU \passthrough{\lstinline!gdb!}. \index{GNU debugger}

\hypertarget{beware-gdb-on-mac-os-x}{%
\subparagraph{Beware gdb on Mac OS X}\label{beware-gdb-on-mac-os-x}}

The examples here assume that you are running
\passthrough{\lstinline!gdb!} on either Linux or FreeBSD. Mac OS X 10.8
does have \passthrough{\lstinline!gdb!} installed, but it's a rather
quirky experience that doesn't reliably interpret the debugging
information contained in the native binaries. This can result in
function names showing up as raw symbols such as
\passthrough{\lstinline!.L101!} instead of their more human-readable
form.

For OCaml 4.1, we'd recommend you do native code debugging on an
alternate platform such as Linux, or manually look at the assembly code
output to map the symbol names onto their precise OCaml functions.

MacOS 10.9 removes \passthrough{\lstinline!gdb!} entirely and uses the
lldb debugger from the LLVM project by default. Many of the guidelines
here still apply since the debug information embedded in the binary
output can be interpreted by lldb (or any other DWARF-aware debugger),
but the command-line interfaces to lldb is different from
\passthrough{\lstinline!gdb!}. Refer to the lldb manual for more
information.

Let's write a mutually recursive function that selects alternating
values from a list. This isn't tail-recursive, so our stack size will
grow as we single-step through the execution:

\begin{lstlisting}[language=Caml]
open Core

let rec take =
  function
  |[] -> []
  |hd::tl -> hd :: (skip tl)
and skip =
  function
  |[] -> []
  |_::tl -> take tl

let () =
  take [1;2;3;4;5;6;7;8;9]
  |> List.map ~f:string_of_int
  |> String.concat ~sep:","
  |> print_endline
\end{lstlisting}

Compile and run this with debugging symbols. You should see the
following output:

\begin{lstlisting}
(executable
  (name      alternate_list)
  (libraries core))
\end{lstlisting}

\begin{lstlisting}[language=bash]
$ dune build alternate_list.exe
$ ./_build/default/alternate_list.exe -ascii -quota 1
1,3,5,7,9
\end{lstlisting}

Now we can run this interactively within \passthrough{\lstinline!gdb!}:

\begin{lstlisting}
$ gdb ./alternate_list.native
GNU gdb (GDB) 7.4.1-debian
Copyright (C) 2012 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "x86_64-linux-gnu".
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>...
Reading symbols from /home/avsm/alternate_list.native...done.
(gdb)
\end{lstlisting}

The \passthrough{\lstinline!gdb!} prompt lets you enter debug
directives. Let's set the program to break just before the first call to
\passthrough{\lstinline!take!}:

\begin{lstlisting}
(gdb) break camlAlternate_list__take_69242
Breakpoint 1 at 0x5658d0: file alternate_list.ml, line 5.
\end{lstlisting}

We used the C symbol name by following the name mangling rules defined
earlier. A convenient way to figure out the full name is by tab
completion. Just type in a portion of the name and press the
\textless tab\textgreater{} key to see a list of possible completions.

Once you've set the breakpoint, start the program executing:

\begin{lstlisting}
(gdb) run
Starting program: /home/avsm/alternate_list.native
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".

Breakpoint 1, camlAlternate_list__take_69242 () at alternate_list.ml:5
4         function
\end{lstlisting}

The binary has run until the first take invocation and stopped, waiting
for further instructions. GDB has lots of features, so let's continue
the program and check the stacktrace after a couple of recursions:

\begin{lstlisting}
(gdb) cont
Continuing.

Breakpoint 1, camlAlternate_list__take_69242 () at alternate_list.ml:5
4         function
(gdb) cont
Continuing.

Breakpoint 1, camlAlternate_list__take_69242 () at alternate_list.ml:5
4         function
(gdb) bt
#0  camlAlternate_list__take_69242 () at alternate_list.ml:4
#1  0x00000000005658e7 in camlAlternate_list__take_69242 () at alternate_list.ml:6
#2  0x00000000005658e7 in camlAlternate_list__take_69242 () at alternate_list.ml:6
#3  0x00000000005659f7 in camlAlternate_list__entry () at alternate_list.ml:14
#4  0x0000000000560029 in caml_program ()
#5  0x000000000080984a in caml_start_program ()
#6  0x00000000008099a0 in ?? ()
#7  0x0000000000000000 in ?? ()
(gdb) clear camlAlternate_list__take_69242
Deleted breakpoint 1
(gdb) cont
Continuing.
1,3,5,7,9
[Inferior 1 (process 3546) exited normally]
\end{lstlisting}

The \passthrough{\lstinline!cont!} command resumes execution after a
breakpoint has paused it, \passthrough{\lstinline!bt!} displays a stack
backtrace, and \passthrough{\lstinline!clear!} deletes the breakpoint so
the application can execute until completion. GDB has a host of other
features we won't cover here, but you can view more guidelines via Mark
Shinwell's talk on
\href{http://www.youtube.com/watch?v=NF2WpWnB-nk\%3C}{``Real-world
debugging in OCaml.''}

One very useful feature of OCaml native code is that C and OCaml share
the same stack. This means that GDB backtraces can give you a combined
view of what's going on in your program \emph{and} runtime library. This
includes any calls to C libraries or even callbacks into OCaml from the
C layer if you're in an environment which embeds the OCaml runtime as a
library.

\hypertarget{profiling-native-code}{%
\subsubsection{Profiling Native Code}\label{profiling-native-code}}

The recording and analysis of where your application spends its
execution time is known as \emph{performance profiling}. OCaml native
code binaries can be profiled just like any other C binary, by using the
name mangling described earlier to map between OCaml variable names and
the profiler output.
\index{profiling}\index{performance profiling}\index{native-code
compiler/performance profiling}

Most profiling tools benefit from having some instrumentation included
in the binary. OCaml supports two such tools:

\begin{itemize}
\item
  GNU \passthrough{\lstinline!gprof!}, to measure execution time and
  call graphs
\item
  The \href{https://perf.wiki.kernel.org/}{Perf} profiling framework in
  modern versions of Linux
\end{itemize}

Note that many other tools that operate on native binaries, such as
Valgrind, will work just fine with OCaml as long as the program is
linked with the \passthrough{\lstinline!-g!} flag to embed debugging
symbols.

\hypertarget{gprof}{%
\paragraph{Gprof}\label{gprof}}

\passthrough{\lstinline!gprof!} produces an execution profile of an
OCaml program by recording a call graph of which functions call one
another, and recording the time these calls take during the program
execution.\index{gprof code profiler}

Getting precise information out of \passthrough{\lstinline!gprof!}
requires passing the \passthrough{\lstinline!-p!} flag to the native
code compiler when compiling \emph{and} linking the binary. This
generates extra code that records profile information to a file called
\passthrough{\lstinline!gmon.out!} when the program is executed. This
profile information can then be examined using
\passthrough{\lstinline!gprof!}.

\hypertarget{perf}{%
\paragraph{Perf}\label{perf}}

Perf is a more modern alternative to \passthrough{\lstinline!gprof!}
that doesn't require you to instrument the binary. Instead, it uses
hardware counters and debug information within the binary to record
information accurately.

Run Perf on a compiled binary to record information first. We'll use our
write barrier benchmark from earlier, which measures memory allocation
versus in-place modification:

\begin{lstlisting}
$ perf record -g ./barrier_bench.native
Estimated testing time 20s (change using -quota SECS).

  Name        Time (ns)             Time 95ci   Percentage
  ----        ---------             ---------   ----------
  mutable     7_306_219   7_250_234-7_372_469        96.83
  immutable   7_545_126   7_537_837-7_551_193       100.00

[ perf record: Woken up 11 times to write data ]
[ perf record: Captured and wrote 2.722 MB perf.data (~118926 samples) ]
perf record -g ./barrier.native
Estimated testing time 20s (change using -quota SECS).

  Name        Time (ns)             Time 95ci   Percentage
  ----        ---------             ---------   ----------
  mutable     7_306_219   7_250_234-7_372_469        96.83
  immutable   7_545_126   7_537_837-7_551_193       100.00

[ perf record: Woken up 11 times to write data ]
[ perf record: Captured and wrote 2.722 MB perf.data (~118926 samples) ]
\end{lstlisting}

When this completes, you can interactively explore the results:

\begin{lstlisting}
$ perf report -g
+  48.86%  barrier.native  barrier.native  [.] camlBarrier__test_immutable_69282
+  30.22%  barrier.native  barrier.native  [.] camlBarrier__test_mutable_69279
+  20.22%  barrier.native  barrier.native  [.] caml_modify
\end{lstlisting}

This trace broadly reflects the results of the benchmark itself. The
mutable benchmark consists of the combination of the call to
\passthrough{\lstinline!test\_mutable!} and the
\passthrough{\lstinline!caml\_modify!} write barrier function in the
runtime. This adds up to slightly over half the execution time of the
application.

Perf has a growing collection of other commands that let you archive
these runs and compare them against each other. You can read more on the
\href{http://perf.wiki.kernel.org}{home page}. \index{frame pointers}

\hypertarget{using-the-frame-pointer-to-get-more-accurate-traces}{%
\subparagraph{Using the Frame Pointer to Get More Accurate
Traces}\label{using-the-frame-pointer-to-get-more-accurate-traces}}

Although Perf doesn't require adding in explicit probes to the binary,
it does need to understand how to unwind function calls so that the
kernel can accurately record the function backtrace for every event.

OCaml stack frames are too complex for Perf to understand directly, and
so it needs the compiler to fall back to using the same conventions as C
for function calls. On 64-bit Intel systems, this means that a special
register known as the \emph{frame pointer} is used to record function
call history.

Using the frame pointer in this fashion means a slowdown (typically
around 3-5\%) since it's no longer available for general-purpose use.
OCaml 4.1 thus makes the frame pointer an optional feature that can be
used to improve the resolution of Perf traces.

OPAM provides a compiler switch that compiles OCaml with the frame
pointer activated:

\begin{lstlisting}
$ opam switch 4.01.0+fp
\end{lstlisting}

Using the frame pointer changes the OCaml calling convention, but OPAM
takes care of recompiling all your libraries with the new interface. You
can read more about this on the OCamlPro
\href{http://www.ocamlpro.com/blog/2012/08/08/profile-native-code.html}{blog}.

\hypertarget{embedding-native-code-in-c}{%
\subsubsection{Embedding Native Code in
C}\label{embedding-native-code-in-c}}

The native code compiler normally links a complete executable, but can
also output a standalone native object file just as the bytecode
compiler can. This object file has no further dependencies on OCaml
except for the runtime
library.\index{libasmrun.a library}\index{native-code compiler/embedding code in
C}

The native code runtime is a different library from the bytecode one,
and is installed as \passthrough{\lstinline!libasmrun.a!} in the OCaml
standard library directory.

Try this custom linking by using the same source files from the bytecode
embedding example earlier in this chapter:

\begin{lstlisting}
$ ocamlopt -output-obj -o embed_native.o embed_me1.ml embed_me2.ml
$ gcc -Wall -I `ocamlc -where` -o final.native embed_native.o main.c \
   -L `ocamlc -where` -lasmrun -ltermcap -lm -ldl
$ ./final.native
Before calling OCaml
hello embedded world 1
hello embedded world 2
After calling OCaml
\end{lstlisting}

The \passthrough{\lstinline!embed\_native.o!} is a standalone object
file that has no further references to OCaml code beyond the runtime
library, just as with the bytecode runtime. Do remember that the link
order of the libraries is significant in modern GNU toolchains
(especially as used in Ubuntu 11.10 and later) that resolve symbols from
left to right in a single
pass.\index{debugging/activating debug runtime}

\hypertarget{activating-the-debug-runtime}{%
\paragraph{Activating the Debug
Runtime}\label{activating-the-debug-runtime}}

Despite your best efforts, it is easy to introduce a bug into some
components, such as C bindings, that causes heap invariants to be
violated. OCaml includes a \passthrough{\lstinline!libasmrund.a!}
variant of the runtime library which is compiled with extra debugging
checks that perform extra memory integrity checks during every garbage
collection cycle. Running these extra checks will abort the program
nearer the point of corruption and help isolate the bug in the C code.

To use the debug library, just link your program with the
\passthrough{\lstinline!-runtime-variant d!} flag:

\begin{lstlisting}[language=bash]
$ ocamlopt -runtime-variant d -verbose -o hello.native hello.ml
+ clang -arch x86_64 -Wno-trigraphs -c -o 'hello.o' '/var/folders/9g/7vjfw6kn7k9bs721d_zjzn7h0000gn/T/camlasm9b916c.s'
+ clang -arch x86_64 -Wno-trigraphs -c -o '/var/folders/9g/7vjfw6kn7k9bs721d_zjzn7h0000gn/T/camlstartup8f1c0d.o' '/var/folders/9g/7vjfw6kn7k9bs721d_zjzn7h0000gn/T/camlstartupf69d9a.s'
+ cc -O2 -fno-strict-aliasing -fwrapv -Wall -D_FILE_OFFSET_BITS=64 -D_REENTRANT -DCAML_NAME_SPACE   -Wl,-no_compact_unwind -o 'hello.native'   '-L/Users/thomas/git/rwo/book/_opam/lib/ocaml'  '/var/folders/9g/7vjfw6kn7k9bs721d_zjzn7h0000gn/T/camlstartup8f1c0d.o' '/Users/thomas/git/rwo/book/_opam/lib/ocaml/std_exit.o' 'hello.o' '/Users/thomas/git/rwo/book/_opam/lib/ocaml/stdlib.a' '/Users/thomas/git/rwo/book/_opam/lib/ocaml/libasmrund.a'
$ ./hello.native
### OCaml runtime: debug mode ###
Initial minor heap size: 256k words
Initial major heap size: 3840k bytes
Initial space overhead: 80%
Initial max overhead: 500%
Initial heap increment: 15%
Initial allocation policy: 0
Initial smoothing window: 1
Hello OCaml World!
\end{lstlisting}

If you get an error that \passthrough{\lstinline!libasmrund.a!} is not
found, it's probably because you're using OCaml 4.00 and not 4.01. It's
only installed by default in the very latest version, which you should
be using via the \passthrough{\lstinline!4.01.0!} OPAM switch. ~

\hypertarget{summarizing-the-file-extensions}{%
\subsection{Summarizing the File
Extensions}\label{summarizing-the-file-extensions}}

We've seen how the compiler uses intermediate files to store various
stages of the compilation toolchain. Here's a cheat sheet of all them in
one place.
\index{files/chart of file extensions}\index{compilation process/file
extensions}

\href{compiler-backend.html\#Table2301}{Table2301} shows the
intermediate files generated by \passthrough{\lstinline!ocamlc!}.

\hypertarget{Table2301}{}
\begin{longtable}[]{@{}ll@{}}
\caption{Intermediate files generated by the OCaml compiler
toolchain}\tabularnewline
\toprule
\begin{minipage}[b]{0.52\columnwidth}\raggedright
Extension\strut
\end{minipage} & \begin{minipage}[b]{0.42\columnwidth}\raggedright
Purpose\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.52\columnwidth}\raggedright
Extension\strut
\end{minipage} & \begin{minipage}[b]{0.42\columnwidth}\raggedright
Purpose\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.52\columnwidth}\raggedright
\passthrough{\lstinline!.ml!}\strut
\end{minipage} & \begin{minipage}[t]{0.42\columnwidth}\raggedright
Source files for compilation unit module implementations.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.52\columnwidth}\raggedright
\passthrough{\lstinline!.mli!}\strut
\end{minipage} & \begin{minipage}[t]{0.42\columnwidth}\raggedright
Source files for compilation unit module interfaces. If missing,
generated from the \passthrough{\lstinline!.ml!} file.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.52\columnwidth}\raggedright
\passthrough{\lstinline!.cmi!}\strut
\end{minipage} & \begin{minipage}[t]{0.42\columnwidth}\raggedright
Compiled module interface from a corresponding
\passthrough{\lstinline!.mli!} source file.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.52\columnwidth}\raggedright
\passthrough{\lstinline!.cmo!}\strut
\end{minipage} & \begin{minipage}[t]{0.42\columnwidth}\raggedright
Compiled bytecode object file of the module implementation.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.52\columnwidth}\raggedright
\passthrough{\lstinline!.cma!}\strut
\end{minipage} & \begin{minipage}[t]{0.42\columnwidth}\raggedright
Library of bytecode object files packed into a single file.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.52\columnwidth}\raggedright
\passthrough{\lstinline!.o!}\strut
\end{minipage} & \begin{minipage}[t]{0.42\columnwidth}\raggedright
C source files are compiled into native object files by the system
\passthrough{\lstinline!cc!}.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.52\columnwidth}\raggedright
\passthrough{\lstinline!.cmt!}\strut
\end{minipage} & \begin{minipage}[t]{0.42\columnwidth}\raggedright
Typed abstract syntax tree for module implementations.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.52\columnwidth}\raggedright
\passthrough{\lstinline!.cmti!}\strut
\end{minipage} & \begin{minipage}[t]{0.42\columnwidth}\raggedright
Typed abstract syntax tree for module interfaces.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.52\columnwidth}\raggedright
\passthrough{\lstinline!.annot!}\strut
\end{minipage} & \begin{minipage}[t]{0.42\columnwidth}\raggedright
Old-style annotation file for displaying
\passthrough{\lstinline!typed!}, superseded by
\passthrough{\lstinline!cmt!} files.\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

The native code compiler generates some additional files (see
\href{compiler-backend.html\#Table2302}{Table2302}).\index{native-code
compiler/files generated by}

\hypertarget{Table2302}{}
\begin{longtable}[]{@{}ll@{}}
\caption{Intermediate outputs produced by the native code OCaml
toolchain}\tabularnewline
\toprule
\begin{minipage}[b]{0.52\columnwidth}\raggedright
Extension\strut
\end{minipage} & \begin{minipage}[b]{0.42\columnwidth}\raggedright
Purpose\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.52\columnwidth}\raggedright
Extension\strut
\end{minipage} & \begin{minipage}[b]{0.42\columnwidth}\raggedright
Purpose\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.52\columnwidth}\raggedright
\passthrough{\lstinline!.o!}\strut
\end{minipage} & \begin{minipage}[t]{0.42\columnwidth}\raggedright
Compiled native object file of the module implementation.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.52\columnwidth}\raggedright
\passthrough{\lstinline!.cmx!}\strut
\end{minipage} & \begin{minipage}[t]{0.42\columnwidth}\raggedright
Contains extra information for linking and cross-module optimization of
the object file.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.52\columnwidth}\raggedright
\passthrough{\lstinline!.cmxa and .a!}\strut
\end{minipage} & \begin{minipage}[t]{0.42\columnwidth}\raggedright
Library of \passthrough{\lstinline!cmx!} and \passthrough{\lstinline!o!}
units, stored in the \passthrough{\lstinline!cmxa!} and
\passthrough{\lstinline!a!} files respectively. These files are always
needed together.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.52\columnwidth}\raggedright
\passthrough{\lstinline!.S!} \emph{or}
\passthrough{\lstinline!.s!}\strut
\end{minipage} & \begin{minipage}[t]{0.42\columnwidth}\raggedright
Assembly language output if \passthrough{\lstinline!-S!} is
specified.\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}
